# Классификация токсичных комментариев

Интернет-магазин «Викишоп» запускает новый сервис. 

Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

Постройте модель со значением метрики качества F1 не меньше 0.75. 

Данные находятся в файле /datasets/toxic_comments.csv. 
Столбец text в нём содержит текст комментария, а toxic — целевой признак.

Алгоритм решения:
- Загрузите и подготовьте данные.
- Обучите разные модели.
- Сделайте выводы.

Содержание

1.  Подготовка
    - 1.1  Загрузка библиотек
    - 1.2  Загрузка датасета
    - 1.3  Подготовка признаков перед обучением
2.  Обучение
    - 2.1  LogisticRegression
    - 2.2  DecisionTreeClassifier
3.  Выводы


## Цель исследования:

На основе собранных данных с разметкой о токсичности правок нужно обучить модель классифицировать комментарии на позитивные и негативные со значением метрики качества F1 не меньше 0.75. Построить модель для такого предсказания, используя полученные знания о машинном обучении для текстов.


## Ход исследования:

Шаг 1. Загрузим данные и выполним поиск лучшего способа балансировки и сравним качество.

Шаг 2. Проанализируем данные и проведем очистку текстов.

Шаг 3. Подготовим признаки перед обучением, с помощью библиотеку spacy проведем лемматизацию.

Шаг 4. Обучим разные модели с различными гиперпараметрами. Сделаем тестовую выборку размером 10% от исходных данных.

Шаг 5. Проверим данные на тестовой выборке и сделаем выводы.


## Итог исследования:

Загружены данные. Проведена предобработка данных. Проанализированы данные.

В отзывах присутствует дисбаланс классов: соотношение положительных комментариев к отрицательным было равно 1:8,84.

Всего комментариев ~ 160 тыс.

Модель решающего дерева с задачей справляется существенно хуже логистической регрессии (F1 0,54 против 0,76 на трейне). Поэтому тестировали модель логистической регрессии, которая на тесте тоже превысила метрику в 0,75, т.е. задача решена.

Параметры модели: {'C': 10, 'warm_start': True}

## Стек технологий:

`pandas`, `numpy`, `scikit-learn`, `LogisticRegression`, `tqdm`, `os`, `re`, `TfidfVectorizer`, `spacy`, `nltk`
